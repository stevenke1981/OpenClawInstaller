# ============================================================
# OpenClaw Docker Compose 設定 (Windows 版)
#
# 使用方法:
#   1. 確保您的 C:\Users\您的使用者名稱\.openclaw 目錄已建立
#      (或執行我們剛才寫的 startup.bat 腳本)
#   2. 編輯設定檔，填入您的 API Key
#   3. 在此檔案所在目錄執行: docker-compose up -d
#   4. 查看日誌: docker-compose logs -f
# ============================================================

version: '3.8'

services:
  openclaw:
    build: .
    image: openclaw:latest
    container_name: openclaw
    restart: unless-stopped
    
    # 環境變數（可選，優先級高於設定檔）
    environment:
      # 修改時區為台北
      - TZ=Asia/Taipei
      # 可以透過環境變數設定敏感資訊
      # - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      # - OPENAI_API_KEY=${OPENAI_API_KEY}
      # - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
    
    # 連接埠映射
    ports:
      - "18789:18789"
    
    # 儲存卷掛載 (Volume)
    volumes:
      # 設定與資料持久化
      # Windows 宿主機路徑使用 ${USERPROFILE} 對應 C:\Users\Username
      # 容器內部路徑維持 /root/... 不變 (因為容器內部是 Linux)
      - ${USERPROFILE}/.openclaw:/root/.openclaw
      
      # 可選：掛載自定義技能目錄
      # - ./custom-skills:/root/.openclaw/skills
    
    # 健康檢查
    healthcheck:
      test: ["CMD", "openclaw", "health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    
    # 日誌設定
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    
    # 網路設定
    networks:
      - openclaw-network

  # 可選：Ollama 本地模型服務
  # 取消註解以啟用本地 AI 模型
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   restart: unless-stopped
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   networks:
  #     - openclaw-network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]

networks:
  openclaw-network:
    driver: bridge

# 如果啟用 ollama，請取消下方註解
# volumes:
#   ollama-data:
